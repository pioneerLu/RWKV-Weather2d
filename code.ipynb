{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PatchEmbedding2D(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, patch_size):\n",
    "        super(PatchEmbedding2D, self).__init__()\n",
    "        self.projection = nn.Conv2d(\n",
    "            in_channels=input_dim,\n",
    "            out_channels=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size\n",
    "        )\n",
    "        self.flatten = nn.Flatten(start_dim=2)  # Flatten spatial dimensions (H, W)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.projection(x)  # (B, embed_dim, H', W')\n",
    "        x = self.flatten(x)  # (B, embed_dim, H'*W')\n",
    "        x = x.transpose(1, 2)  # (B, H'*W', embed_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchRecovery2D(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, patch_size):\n",
    "        super(PatchRecovery2D, self).__init__()\n",
    "        self.reconstruction = nn.ConvTranspose2d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=output_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x, spatial_shape):\n",
    "        # Reshape to (B, embed_dim, H', W') for ConvTranspose2d\n",
    "        B, N, C = x.shape\n",
    "        H, W = spatial_shape\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)\n",
    "        return self.reconstruction(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthSpecificBlock:\n",
    "  def __init__(self, dim, drop_path_ratio, heads):\n",
    "    # Define the window size of the neural network \n",
    "    self.window_size = (2, 6, 12)\n",
    "\n",
    "    # Initialize serveral operations\n",
    "    self.drop_path = DropPath(drop_rate=drop_path_ratio)\n",
    "    self.norm1 = LayerNorm(dim)\n",
    "    self.norm2 = LayerNorm(dim)\n",
    "    self.linear = MLP(dim, 0)\n",
    "    self.attention = EarthAttention3D(dim, heads, 0, self.window_size)\n",
    "\n",
    "  def forward(self, x, Z, H, W, roll):\n",
    "    # Save the shortcut for skip-connection\n",
    "    shortcut = x\n",
    "\n",
    "    # Reshape input to three dimensions to calculate window attention\n",
    "    reshape(x, target_shape=(x.shape[0], Z, H, W, x.shape[2]))\n",
    "\n",
    "    # Zero-pad input if needed\n",
    "    x = pad3D(x)\n",
    "\n",
    "    # Store the shape of the input for restoration\n",
    "    ori_shape = x.shape\n",
    "\n",
    "    if roll:\n",
    "      # Roll x for half of the window for 3 dimensions\n",
    "      x = roll3D(x, shift=[self.window_size[0]//2, self.window_size[1]//2, self.window_size[2]//2])\n",
    "      # Generate mask of attention masks\n",
    "      # If two pixels are not adjacent, then mask the attention between them\n",
    "      # Your can set the matrix element to -1000 when it is not adjacent, then add it to the attention\n",
    "      mask = gen_mask(x)\n",
    "    else:\n",
    "      # e.g., zero matrix when you add mask to attention\n",
    "      mask = no_mask\n",
    "\n",
    "    # Reorganize data to calculate window attention\n",
    "    x_window = reshape(x, target_shape=(x.shape[0], Z//window_size[0], window_size[0], H // window_size[1], window_size[1], W // window_size[2], window_size[2], x.shape[-1]))\n",
    "    x_window = TransposeDimensions(x_window, (0, 1, 3, 5, 2, 4, 6, 7))\n",
    "\n",
    "    # Get data stacked in 3D cubes, which will further be used to calculated attention among each cube\n",
    "    x_window = reshape(x_window, target_shape=(-1, window_size[0]* window_size[1]*window_size[2], x.shape[-1]))\n",
    "\n",
    "    # Apply 3D window attention with Earth-Specific bias\n",
    "    x_window = self.attention(x, mask)\n",
    "\n",
    "    # Reorganize data to original shapes\n",
    "    x = reshape(x_window, target_shape=((-1, Z // window_size[0], H // window_size[1], W // window_size[2], window_size[0], window_size[1], window_size[2], x_window.shape[-1])))\n",
    "    x = TransposeDimensions(x, (0, 1, 4, 2, 5, 3, 6, 7))\n",
    "\n",
    "    # Reshape the tensor back to its original shape\n",
    "    x = reshape(x_window, target_shape=ori_shape)\n",
    "\n",
    "    if roll:\n",
    "      # Roll x back for half of the window\n",
    "      x = roll3D(x, shift=[-self.window_size[0]//2, -self.window_size[1]//2, -self.window_size[2]//2])\n",
    "\n",
    "    # Crop the zero-padding\n",
    "    x = Crop3D(x)\n",
    "\n",
    "    # Reshape the tensor back to the input shape\n",
    "    x = reshape(x, target_shape=(x.shape[0], x.shape[1]*x.shape[2]*x.shape[3], x.shape[4]))\n",
    "\n",
    "    # Main calculation stages\n",
    "    x = shortcut + self.drop_path(self.norm1(x))\n",
    "    x = x + self.drop_path(self.norm2(self.linear(x)))\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
