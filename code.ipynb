{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rwkv/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 1261\n",
      "Number of train samples: 1261\n",
      "Number of train samples: 1261\n"
     ]
    }
   ],
   "source": [
    "from dataset_test import RWKVWeatherDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = RWKVWeatherDataset('/home/rwkv/RWKV-TS/WeatherBench/era5_data/ERA5_merged(2010-2018).nc',flag='train',split=0.8)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve embedding and recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PatchEmbedding3D(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, patch_size):\n",
    "        super(PatchEmbedding3D, self).__init__()\n",
    "        self.projection = nn.Conv3d(\n",
    "            in_channels=input_dim,\n",
    "            out_channels=embed_dim,\n",
    "            kernel_size=patch_size,  # no overlapping\n",
    "            stride=patch_size,\n",
    "            # padding=(15, 0, 0)\n",
    "        )\n",
    "        self.flatten = nn.Flatten(start_dim=2)  # Flatten spatial and time dimensions (T, H, W)\n",
    "\n",
    "    def forward(self, x):  # (B, C, T, H, W)\n",
    "        x = self.projection(x)  # (B, embed_dim, T', H', W')\n",
    "        print(x.shape)\n",
    "        x = self.flatten(x)  # (B, embed_dim, T'*H'*W')\n",
    "        x = x.transpose(1, 2)  # (B, T'*H'*W', embed_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PatchRecovery3D(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, patch_size):\n",
    "        super(PatchRecovery3D, self).__init__()\n",
    "        self.reconstruction = nn.ConvTranspose3d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=output_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size,\n",
    "            # padding=patch_size\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x, temporal_shape, spatial_shape):\n",
    "        # Reshape to (B, embed_dim, T', H', W') for ConvTranspose3d\n",
    "        B, N, C = x.shape\n",
    "        T, H, W = temporal_shape, *spatial_shape\n",
    "        x = x.transpose(1, 2).view(B, C, T, H, W)\n",
    "        return self.reconstruction(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 1261\n",
      "Number of train samples: 1261\n",
      "input shape: torch.Size([4, 5, 10, 176, 156])\n",
      "torch.Size([4, 128, 5, 44, 39])\n",
      "embeddings shape: torch.Size([4, 8580, 128])\n",
      "recovered shape: torch.Size([4, 5, 10, 176, 156])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m patch_embedding \u001b[38;5;241m=\u001b[39m PatchEmbedding3D(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      2\u001b[0m patch_recovery \u001b[38;5;241m=\u001b[39m PatchRecovery3D(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)) \n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m patch_embedding(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/RWKV-TS/WeatherBench/dataset_test.py:75\u001b[0m, in \u001b[0;36mRWKVWeatherDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     67\u001b[0m     target\u001b[38;5;241m.\u001b[39mappend(target_data)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# sample = {\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#     'input': np.concatenate(input_points, axis=1),\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#     'target': np.concatenate(target, axis=1),\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m     74\u001b[0m sample \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_points\u001b[49m\u001b[43m)\u001b[49m[idx],\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(target)[idx],\n\u001b[1;32m     77\u001b[0m }\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# patch_embedding = PatchEmbedding3D(5, 128, (2,4,4))\n",
    "# patch_recovery = PatchRecovery3D(5, 128, (2,4,4)) \n",
    "# for data in dataloader:\n",
    "#     print(\"input shape:\", data['input'].shape)\n",
    "#     embeddings = patch_embedding(data['input'])\n",
    "#     print(\"embeddings shape:\", embeddings.shape)\n",
    "#     recover = patch_recovery(embeddings,5,(44,39))\n",
    "#     print(\"recovered shape:\", recover.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWKV-Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/rwkv/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module wkv6, skipping build step...\n",
      "Loading extension module wkv6...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, math, gc, importlib\n",
    "import torch\n",
    "# torch._C._jit_set_profiling_executor(True)\n",
    "# torch._C._jit_set_profiling_mode(True)\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import rank_zero_info, rank_zero_only\n",
    "from pytorch_lightning.strategies import DeepSpeedStrategy\n",
    "from transformers import CLIPVisionModel\n",
    "if importlib.util.find_spec('deepspeed'):\n",
    "    import deepspeed\n",
    "    from deepspeed.ops.adam import DeepSpeedCPUAdam, FusedAdam\n",
    "\n",
    "def __nop(ob):\n",
    "    return ob\n",
    "\n",
    "MyModule = nn.Module\n",
    "MyFunction = __nop\n",
    "# if os.environ[\"RWKV_JIT_ON\"] == \"1\":\n",
    "\n",
    "MyModule = torch.jit.ScriptModule\n",
    "MyFunction = torch.jit.script_method\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "# CUDA Kernel\n",
    "########################################################################################################\n",
    "\n",
    "from torch.utils.cpp_extension import load\n",
    "\n",
    "HEAD_SIZE = 64\n",
    "wkv6_cuda = load(name=\"wkv6\", sources=[\"cuda/wkv6_op.cpp\", f\"cuda/wkv6_cuda.cu\"],\n",
    "                    verbose=True, extra_cuda_cflags=[\"-res-usage\", \"--use_fast_math\", \"-O3\", \"-Xptxas -O3\", \"--extra-device-vectorization\", f\"-D_N_={HEAD_SIZE}\", f\"-D_T_={int(10)}\"])\n",
    "    \n",
    "class WKV_6(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, B, T, C, H, r, k, v, w, u):\n",
    "        with torch.no_grad():\n",
    "            assert r.dtype == torch.bfloat16\n",
    "            assert k.dtype == torch.bfloat16\n",
    "            assert v.dtype == torch.bfloat16\n",
    "            assert w.dtype == torch.bfloat16\n",
    "            assert u.dtype == torch.bfloat16\n",
    "            assert HEAD_SIZE == C // H\n",
    "            ctx.B = B\n",
    "            ctx.T = T\n",
    "            ctx.C = C\n",
    "            ctx.H = H\n",
    "            assert r.is_contiguous()\n",
    "            assert k.is_contiguous()\n",
    "            assert v.is_contiguous()\n",
    "            assert w.is_contiguous()\n",
    "            assert u.is_contiguous()\n",
    "            ew = (-torch.exp(w.float())).contiguous()\n",
    "            ctx.save_for_backward(r, k, v, ew, u)\n",
    "            y = torch.empty((B, T, C), device=r.device, dtype=torch.bfloat16, memory_format=torch.contiguous_format)#.uniform_(-100, 100)\n",
    "            wkv6_cuda.forward(B, T, C, H, r, k, v, ew, u, y)\n",
    "            return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, gy):\n",
    "        with torch.no_grad():\n",
    "            assert gy.dtype == torch.bfloat16\n",
    "            B = ctx.B\n",
    "            T = ctx.T\n",
    "            C = ctx.C\n",
    "            H = ctx.H\n",
    "            assert gy.is_contiguous()\n",
    "            r, k, v, ew, u = ctx.saved_tensors\n",
    "            gr = torch.empty((B, T, C), device=gy.device, requires_grad=False, dtype=torch.bfloat16, memory_format=torch.contiguous_format)#.uniform_(-100, 100)\n",
    "            gk = torch.empty((B, T, C), device=gy.device, requires_grad=False, dtype=torch.bfloat16, memory_format=torch.contiguous_format)#.uniform_(-100, 100)\n",
    "            gv = torch.empty((B, T, C), device=gy.device, requires_grad=False, dtype=torch.bfloat16, memory_format=torch.contiguous_format)#.uniform_(-100, 100)\n",
    "            gw = torch.empty((B, T, C), device=gy.device, requires_grad=False, dtype=torch.bfloat16, memory_format=torch.contiguous_format)#.uniform_(-100, 100)\n",
    "            gu = torch.empty((B, C), device=gy.device, requires_grad=False, dtype=torch.bfloat16, memory_format=torch.contiguous_format)#.uniform_(-100, 100)\n",
    "            wkv6_cuda.backward(B, T, C, H, r, k, v, ew, u, gy, gr, gk, gv, gw, gu)\n",
    "            gu = torch.sum(gu, 0).view(H, C//H)\n",
    "            return (None, None, None, None, gr, gk, gv, gw, gu)\n",
    "\n",
    "def RUN_CUDA_RWKV6(B, T, C, H, r, k, v, w, u):\n",
    "    return WKV_6.apply(B, T, C, H, r, k, v, w, u)\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "class RWKV_Tmix_x060(MyModule):\n",
    "    def __init__(self, args, layer_id):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.layer_id = layer_id\n",
    "\n",
    "        self.head_size = 64\n",
    "        self.n_head = args.dim_att // self.head_size\n",
    "        assert args.dim_att % self.n_head == 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # print(args.n_layer)\n",
    "            ratio_0_to_1 = layer_id / (args.n_layer - 1)  # 0 to 1\n",
    "            ratio_1_to_almost0 = 1.0 - (layer_id / args.n_layer)  # 1 to ~0\n",
    "            ddd = torch.ones(1, 1, args.n_embd)\n",
    "            for i in range(args.n_embd):\n",
    "                ddd[0, 0, i] = i / args.n_embd\n",
    "\n",
    "            # fancy time_mix\n",
    "            self.time_maa_x = nn.Parameter(1.0 - torch.pow(ddd, ratio_1_to_almost0))\n",
    "            self.time_maa_w = nn.Parameter(1.0 - torch.pow(ddd, ratio_1_to_almost0))\n",
    "            self.time_maa_k = nn.Parameter(1.0 - torch.pow(ddd, ratio_1_to_almost0))\n",
    "            self.time_maa_v = nn.Parameter(1.0 - (torch.pow(ddd, ratio_1_to_almost0) + 0.3 * ratio_0_to_1))\n",
    "            self.time_maa_r = nn.Parameter(1.0 - torch.pow(ddd, 0.5 * ratio_1_to_almost0))\n",
    "            self.time_maa_g = nn.Parameter(1.0 - torch.pow(ddd, 0.5 * ratio_1_to_almost0))\n",
    "\n",
    "            D_MIX_LORA = 32 # generate TIME_MIX for w,k,v,r,g\n",
    "            if args.n_embd >= 4096:\n",
    "                D_MIX_LORA = 64\n",
    "            self.time_maa_w1 = nn.Parameter(torch.zeros(args.n_embd, D_MIX_LORA*5))\n",
    "            self.time_maa_w2 = nn.Parameter(torch.zeros(5, D_MIX_LORA, args.n_embd).uniform_(-0.01, 0.01))\n",
    "\n",
    "            # fancy time_decay\n",
    "            decay_speed = torch.ones(args.dim_att)\n",
    "            for n in range(args.dim_att):\n",
    "                decay_speed[n] = -6 + 5 * (n / (args.dim_att - 1)) ** (0.7 + 1.3 * ratio_0_to_1)\n",
    "            self.time_decay = nn.Parameter(decay_speed.reshape(1,1,args.dim_att))\n",
    "\n",
    "            D_DECAY_LORA = 64\n",
    "            if args.n_embd >= 4096:\n",
    "                D_DECAY_LORA = 128\n",
    "            self.time_decay_w1 = nn.Parameter(torch.zeros(args.n_embd, D_DECAY_LORA))\n",
    "            self.time_decay_w2 = nn.Parameter(torch.zeros(D_DECAY_LORA, args.dim_att).uniform_(-0.01, 0.01))\n",
    "\n",
    "            tmp = torch.zeros(args.dim_att)\n",
    "            for n in range(args.dim_att):\n",
    "                zigzag = ((n + 1) % 3 - 1) * 0.1\n",
    "                tmp[n] = ratio_0_to_1 * (1 - (n / (args.dim_att - 1))) + zigzag\n",
    "\n",
    "            self.time_faaaa = nn.Parameter(tmp.reshape(self.n_head, self.head_size))\n",
    "\n",
    "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
    "        self.receptance = nn.Linear(args.n_embd, args.dim_att, bias=False)\n",
    "        self.key = nn.Linear(args.n_embd, args.dim_att, bias=False)\n",
    "\n",
    "        self.value = nn.Linear(args.n_embd, args.dim_att, bias=False)\n",
    "        self.output = nn.Linear(args.dim_att, args.n_embd, bias=False)\n",
    "        self.gate = nn.Linear(args.n_embd, args.dim_att, bias=False)\n",
    "        self.ln_x = nn.GroupNorm(self.n_head, args.dim_att, eps=(1e-5)*(args.head_size_divisor**2))\n",
    "\n",
    "    @MyFunction\n",
    "    def jit_func(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        xx = self.time_shift(x) - x\n",
    "\n",
    "        xxx = x + xx * self.time_maa_x\n",
    "        xxx = torch.tanh(xxx @ self.time_maa_w1).view(B*T, 5, -1).transpose(0, 1)\n",
    "        xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
    "        mw, mk, mv, mr, mg = xxx.unbind(dim=0)\n",
    "\n",
    "        xw = x + xx * (self.time_maa_w + mw)\n",
    "        xk = x + xx * (self.time_maa_k + mk)\n",
    "        xv = x + xx * (self.time_maa_v + mv)\n",
    "        xr = x + xx * (self.time_maa_r + mr)\n",
    "        xg = x + xx * (self.time_maa_g + mg)\n",
    "\n",
    "        r = self.receptance(xr)\n",
    "        k = self.key(xk)\n",
    "        v = self.value(xv)\n",
    "        g = F.silu(self.gate(xg))\n",
    "\n",
    "        ww = torch.tanh(xw @ self.time_decay_w1) @ self.time_decay_w2\n",
    "        w = self.time_decay + ww\n",
    "\n",
    "        return r, k, v, g, w\n",
    "\n",
    "    @MyFunction\n",
    "    def jit_func_2(self, x, g):\n",
    "        B, T, C = x.size()\n",
    "        x = x.view(B * T, C)\n",
    "        \n",
    "        x = self.ln_x(x).view(B, T, C)\n",
    "        x = self.output(x * g)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        H = self.n_head\n",
    "\n",
    "        r, k, v, g, w = self.jit_func(x)\n",
    "        x = RUN_CUDA_RWKV6(B, T, C, H, r, k, v, w, u=self.time_faaaa)\n",
    "\n",
    "        return self.jit_func_2(x, g)\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "class RWKV_CMix_x060(MyModule):\n",
    "    def __init__(self, args, layer_id):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.layer_id = layer_id\n",
    "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
    "\n",
    "        with torch.no_grad():  # fancy init of time_mix\n",
    "            ratio_1_to_almost0 = 1.0 - (layer_id / args.n_layer)  # 1 to ~0\n",
    "            ddd = torch.ones(1, 1, args.n_embd)\n",
    "            for i in range(args.n_embd):\n",
    "                ddd[0, 0, i] = i / args.n_embd\n",
    "            self.time_maa_k = nn.Parameter(1.0 - torch.pow(ddd, ratio_1_to_almost0))\n",
    "            self.time_maa_r = nn.Parameter(1.0 - torch.pow(ddd, ratio_1_to_almost0))\n",
    "\n",
    "        self.key = nn.Linear(args.n_embd, args.dim_ffn, bias=False)\n",
    "        self.receptance = nn.Linear(args.n_embd, args.n_embd, bias=False)\n",
    "        self.value = nn.Linear(args.dim_ffn, args.n_embd, bias=False)\n",
    "\n",
    "    @MyFunction\n",
    "    def forward(self, x):\n",
    "        xx = self.time_shift(x) - x\n",
    "        xk = x + xx * self.time_maa_k\n",
    "        xr = x + xx * self.time_maa_r\n",
    "\n",
    "        k = self.key(xk)\n",
    "        k = torch.relu(k) ** 2\n",
    "        kv = self.value(k)\n",
    "        return torch.sigmoid(self.receptance(xr)) * kv\n",
    "    \n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, args, layer_id):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.layer_id = layer_id\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(args.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(args.n_embd)\n",
    "\n",
    "        if self.layer_id == 0:\n",
    "            self.ln0 = nn.LayerNorm(args.n_embd)\n",
    "\n",
    "        self.att = RWKV_Tmix_x060(args, layer_id)\n",
    "        self.ffn = RWKV_CMix_x060(args, layer_id)\n",
    "\n",
    "        if args.dropout > 0:\n",
    "            self.drop0 = nn.Dropout(p = args.dropout)\n",
    "            self.drop1 = nn.Dropout(p = args.dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.layer_id == 0:\n",
    "            x = self.ln0(x)\n",
    "\n",
    "        x = x + self.att(self.ln1(x))\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class L2Wrap(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, loss, y):\n",
    "        ctx.save_for_backward(y)\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        y = ctx.saved_tensors[0]\n",
    "        # to encourage the logits to be close to 0\n",
    "        factor = 1e-4 / (y.shape[0] * y.shape[1])\n",
    "        maxx, ids = torch.max(y, -1, keepdim=True)\n",
    "        gy = torch.zeros_like(y)\n",
    "        gy.scatter_(-1, ids, maxx * factor)\n",
    "        return (grad_output, gy)\n",
    "    \n",
    "\n",
    "\n",
    "class RWKV_Layer(pl.LightningModule):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.emb = nn.Embedding(args.vocab_size, args.n_embd)\n",
    "        self.blocks = nn.ModuleList([Block(args, i) for i in range(args.n_layer)])\n",
    "        # print(args.n_layer)\n",
    "        self.ln_out = nn.LayerNorm(args.n_embd)\n",
    "        self.head = nn.Linear(args.n_embd, args.vocab_size, bias=False)\n",
    "\n",
    "        if args.dropout > 0:\n",
    "            self.drop0 = nn.Dropout(p = args.dropout)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        trainable_params = [p for p in self.parameters() if p.requires_grad]\n",
    "        optim_groups = [{\"params\": trainable_params, \"weight_decay\": self.args.weight_decay}]\n",
    "        if self.deepspeed_offload:\n",
    "            return DeepSpeedCPUAdam(optim_groups, lr=self.args.lr_init, betas=self.args.betas, eps=self.args.adam_eps, bias_correction=True, adamw_mode=True, amsgrad=False)\n",
    "        return FusedAdam(optim_groups, lr=self.args.lr_init, betas=self.args.betas, eps=self.args.adam_eps, bias_correction=True, adam_w_mode=True, amsgrad=False)\n",
    "\n",
    "    @property\n",
    "    def deepspeed_offload(self) -> bool:\n",
    "        strategy = self.trainer.strategy\n",
    "        if isinstance(strategy, DeepSpeedStrategy):\n",
    "            cfg = strategy.config[\"zero_optimization\"]\n",
    "            return cfg.get(\"offload_optimizer\") or cfg.get(\"offload_param\")\n",
    "        return False\n",
    "\n",
    "    def forward(self, x):\n",
    "        args = self.args\n",
    "        if args.dropout > 0:\n",
    "            x = self.drop0(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            if args.grad_cp == 1:\n",
    "                x = deepspeed.checkpointing.checkpoint(block, x)\n",
    "            else:\n",
    "                x = block(x)\n",
    "\n",
    "        x = self.ln_out(x)\n",
    "\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        idx, targets = batch\n",
    "        logits = self(idx)\n",
    "        loss = F.mse_loss(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return L2Wrap.apply(loss, logits)\n",
    "\n",
    "    def training_step_end(self, batch_parts):\n",
    "        if pl.__version__[0]!='2':\n",
    "            all = self.all_gather(batch_parts)\n",
    "            if self.trainer.is_global_zero:\n",
    "                self.trainer.my_loss_all = all\n",
    "\n",
    "##Not sure below\n",
    "class DownSample(nn.Module):\n",
    "  def __init__(self, dim):\n",
    "    '''Down-sampling operation'''\n",
    "    super().__init__()\n",
    "    self.conv_down = nn.Conv2d(4*dim,2*dim,kernel_size=1,stride=1,padding='same')\n",
    "    self.norm = nn.LayerNorm(4*dim)\n",
    "  \n",
    "  def forward(self, x, H, W):\n",
    "    # x (B,'H*W',dim)\n",
    "    # Reshape x to three dimensions for downsampling\n",
    "    x = x.view(x.shape[0], H, W, x.shape[-1])\n",
    "\n",
    "    # Padding the input to facilitate downsampling\n",
    "    # x = Pad3D(x)\n",
    "\n",
    "    H, W = x.shape[1], x.shape[2]\n",
    "    # Reshape x to facilitate downsampling\n",
    "    x = x.view(x.shape[0], H//2* W//2, x.shape[-1])\n",
    "    x = self.norm(x)\n",
    "    x = self.conv_down(x)\n",
    "    return x\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    pass\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    pass\n",
    "class Encoder(nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "class RWKV_Weather(pl.LightningModule):\n",
    "    def __init__(self,args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.layer1 = RWKV_Layer(args)\n",
    "        self.layer2 = RWKV_Layer(args)\n",
    "        self.layer3 = RWKV_Layer(args)\n",
    "        self.layer4 = RWKV_Layer(args)\n",
    "        # self.downsample = DownSample(args.n_embd)\n",
    "        # self.upsample = UpSample(args.n_embd)\n",
    "        self.patch_embed = PatchEmbedding3D(5,args.n_embd,(2,4,4))###\n",
    "        self.patch_reovery = PatchRecovery3D(5, args.n_embd,(2,4,4))###\n",
    "        if args.load_model:\n",
    "            self.load_rwkv_from_pretrained(args.load_model)\n",
    "\n",
    "    def load_rwkv_from_pretrained(self, path):\n",
    "        self.rwkv.load_state_dict(torch.load(path, map_location=\"cpu\"))\n",
    "    \n",
    "    def forward(self,samples):\n",
    "        x,y= samples['input'],samples['target']\n",
    "        \n",
    "        x = self.patch_embed(x)\n",
    "        x = self.layer1(x)\n",
    "        print(x.shape)\n",
    "        skip = x\n",
    "\n",
    "        # x = self.downsample(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x= self.layer3(x)\n",
    "        # x = self.upsample(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x + skip\n",
    "        x = self.patch_reovery(x,5,(44,39))\n",
    "        return x,y\n",
    "    \n",
    "    def weighted_temporal_consistency_loss(predict_frames, target_frames, weights):\n",
    "        \"\"\"\n",
    "        param predict_frames: [N, C, H, W]\n",
    "        param target_frames:  [N, C, H, W]\n",
    "        param weights: [N-1]\n",
    "        \"\"\"\n",
    "        num_frames = predict_frames.size(0)\n",
    "        pred_diffs = predict_frames[1:] - predict_frames[:-1]\n",
    "        target_diffs = target_frames[1:] - target_frames[:-1]\n",
    "        assert len(weights) == num_frames - 1\n",
    "        weights = torch.tensor(weights, dtype=torch.float32, device=predict_frames.device)\n",
    "        weights = torch.tensor(weights, dtype=torch.float32, device=predict_frames.device).view(-1, 1, 1, 1)\n",
    "        loss = (weights * F.mse_loss(pred_diffs, target_diffs, reduction='none')).mean()\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs, targets = self(batch)  \n",
    "\n",
    "        loss1 = F.mse_loss(outputs, targets)\n",
    "        weights = torch.ones(len(outputs) - 1, device=outputs.device)  ###\n",
    "        loss2 = self.weighted_temporal_consistency_loss(outputs, targets, weights)###\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        self.log(\"batch_loss\", loss, on_step=True, on_epoch=False, prog_bar=True) \n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        all_losses = [x['loss'] for x in outputs if 'loss' in x]\n",
    "        train_loss = sum(all_losses) / len(all_losses)\n",
    "        self.log(\"train_loss\", train_loss, sync_dist=True)\n",
    "        my_lr = self.trainer.optimizers[0].param_groups[0][\"lr\"]\n",
    "        self.log(\"my_lr\", my_lr, sync_dist=True)\n",
    "\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs, targets = self(batch)\n",
    "        val_loss = F.mse_loss(outputs, targets)\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return {\"val_loss\": val_loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_losses = [x['val_loss'] for x in outputs if 'val_loss' in x]\n",
    "        if val_losses:\n",
    "            avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "            self.log(\"epoch_val_loss\", avg_val_loss, sync_dist=True, prog_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, input) -> list[int]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "class RWKV_weather(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--load_model\", default=\"\", type=str, help=\"path of rwkv model\")  # full path, with .pth\n",
    "parser.add_argument(\"--model_path\", type=str, default=None, help=\"path of time series rwkv\") # \n",
    "parser.add_argument(\"--wandb\", default=\"\", type=str)  # wandb project name. if \"\" then don't use wandb\n",
    "parser.add_argument(\"--proj_dir\", default=\"out\", type=str)\n",
    "parser.add_argument(\"--random_seed\", default=\"-1\", type=int)\n",
    "\n",
    "parser.add_argument(\"--data_file\", default=\"\", type=str)\n",
    "parser.add_argument(\"--data_type\", default=\"utf-8\", type=str)\n",
    "parser.add_argument(\"--vocab_size\", default=65536, type=int)  # vocab_size = 0 means auto (for char-level LM and .txt data)\n",
    "\n",
    "parser.add_argument(\"--ctx_len\", default=10, type=int)\n",
    "parser.add_argument(\"--epoch_steps\", default=100, type=int)  # a mini \"epoch\" has [epoch_steps] steps\n",
    "parser.add_argument(\"--epoch_count\", default=20, type=int)  # train for this many \"epochs\". will continue afterwards with lr = lr_final\n",
    "parser.add_argument(\"--epoch_begin\", default=0, type=int)  # if you load a model trained for x \"epochs\", set epoch_begin = x\n",
    "parser.add_argument(\"--epoch_save\", default=5, type=int)  # save the model every [epoch_save] \"epochs\"\n",
    "\n",
    "parser.add_argument(\"--micro_bsz\", default=12, type=int)  # micro batch size (batch size per GPU)\n",
    "parser.add_argument(\"--n_layer\", default=24, type=int)\n",
    "parser.add_argument(\"--n_embd\", default=512, type=int)\n",
    "parser.add_argument(\"--dim_att\", default=512, type=int)\n",
    "parser.add_argument(\"--dim_ffn\", default=0, type=int)\n",
    "parser.add_argument(\"--pre_ffn\", default=0, type=int)  # replace first att layer by ffn (sometimes better)\n",
    "parser.add_argument(\"--head_size_a\", default=64, type=int)\n",
    "parser.add_argument(\"--head_size_divisor\", default=8, type=int)\n",
    "# parser.add_argument(\"--precision\", default='bf16')\n",
    "parser.add_argument(\"--lr_init\", default=6e-4, type=float)  # 6e-4 for L12-D768, 4e-4 for L24-D1024, 3e-4 for L24-D2048\n",
    "parser.add_argument(\"--lr_final\", default=1e-5, type=float)\n",
    "parser.add_argument(\"--warmup_steps\", default=-1, type=int)  # try 50 if you load a model\n",
    "parser.add_argument(\"--beta1\", default=0.9, type=float)\n",
    "parser.add_argument(\"--beta2\", default=0.99, type=float)  # use 0.999 when your model is close to convergence\n",
    "parser.add_argument(\"--adam_eps\", default=1e-8, type=float)\n",
    "parser.add_argument(\"--grad_cp\", default=0, type=int)  # gradient checkpt: saves VRAM, but slower\n",
    "parser.add_argument(\"--dropout\", default=0, type=float) # try 0.01 / 0.02 / 0.05 / 0.1\n",
    "parser.add_argument(\"--weight_decay\", default=0, type=float) # try 0.1 / 0.01 / 0.001\n",
    "parser.add_argument(\"--weight_decay_final\", default=-1, type=float)\n",
    "parser.add_argument(\"--ds_bucket_mb\", default=200, type=int)  # deepspeed bucket size in MB. 200 seems enough\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "args.precision = 'bf16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rwkv/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "Number of train samples: 1261\n",
      "Number of train samples: 1261\n",
      "torch.Size([4, 512, 5, 44, 39])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(args\u001b[38;5;241m.\u001b[39mn_layer)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[56], line 382\u001b[0m, in \u001b[0;36mRWKV_Weather.forward\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    379\u001b[0m x,y\u001b[38;5;241m=\u001b[39m samples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m],samples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    381\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(x)\n\u001b[0;32m--> 382\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    384\u001b[0m skip \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[56], line 308\u001b[0m, in \u001b[0;36mRWKV_Layer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    306\u001b[0m         x \u001b[38;5;241m=\u001b[39m deepspeed\u001b[38;5;241m.\u001b[39mcheckpointing\u001b[38;5;241m.\u001b[39mcheckpoint(block, x)\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_out(x)\n\u001b[1;32m    312\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[56], line 247\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    245\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln0(x)\n\u001b[0;32m--> 247\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[56], line 186\u001b[0m, in \u001b[0;36mRWKV_Tmix_x060.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head\n\u001b[1;32m    185\u001b[0m r, k, v, g, w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit_func(x)\n\u001b[0;32m--> 186\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mRUN_CUDA_RWKV6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_faaaa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit_func_2(x, g)\n",
      "Cell \u001b[0;32mIn[56], line 81\u001b[0m, in \u001b[0;36mRUN_CUDA_RWKV6\u001b[0;34m(B, T, C, H, r, k, v, w, u)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRUN_CUDA_RWKV6\u001b[39m(B, T, C, H, r, k, v, w, u):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWKV_6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[56], line 40\u001b[0m, in \u001b[0;36mWKV_6.forward\u001b[0;34m(ctx, B, T, C, H, r, k, v, w, u)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, B, T, C, H, r, k, v, w, u):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 40\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m r\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m k\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m v\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model =RWKV_Weather(args)\n",
    "print(args.n_layer)\n",
    "for data in dataloader:\n",
    "    model(data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
